<p align="center">

  <h1 align="center"> SplatLoc: 3D Gaussian Splatting-based Visual Localization for Augmented Reality
  </h1>
  <p align="center">
    <a href="https://zhaihongjia.github.io/"><strong>Hongjia Zhai</strong></a>
    ·
    <a href="https://github.com/xyzhang77"><strong>Xiyu Zhang</strong></a>
    ·
    <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=krMWXqMAAAAJ"><strong>Boming Zhao</strong></a>
    ·
    <a href="https://scholar.google.com/citations?hl=zh-CN&user=vn89ztQAAAAJ&view_op=list_works&sortby=pubdate"><strong>Hai Li</strong></a>
    ·
    <a href="https://scholar.google.com/citations?hl=en&user=_0lKGnkAAAAJ&view_op=list_works&sortby=pubdate"><strong>Yijia He</strong></a>
    ·
    <a href="https://zhpcui.github.io/"><strong>Zhaopeng Cui</strong></a>
    ·
    <a href="http://www.cad.zju.edu.cn/home/bao/"><strong>Hujun Bao</strong></a>
    ·
    <a href="http://www.cad.zju.edu.cn/home/gfzhang/"><strong>Guofeng Zhang</strong></a>
  </p>

[comment]: <> (<h2 align="center">PAPER</h2>)
  <h3 align="center"><a href="https://arxiv.org/abs/2409.14067">Paper</a> | <a href="https://zju3dv.github.io/splatloc/">Project Page</a></h3>
  <div align="center"></div>

  <a href="">
    <img src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/images/teaser.png" alt="gui" width="100%">
  </a>
</p>
<p align="center">
We present <a href="https://arxiv.org/abs/2409.14067">SplatLoc</a>, an efficient and novel visual localization approach designed for Augmented Reality (AR). As illustrated in the figure, our system utilizes monocular RGB-D frames to reconstruct the scene using 3D Gaussian primitives. Additionally, with our learned unbiased 3D descriptor fields, we achieve 6-DoF camera pose estimation through precise 2D-3D feature matching. We demonstrate the potential AR applications of our system, such as virtual content insertion and physical collision simulation. We highlight virtual objects with red boxes.
</p>
<br>

## Updates
- [20204.11.25]: update visualization codes of the localization process.
- [20204.12.02]: update preprocess codes to generate retrieval results, 2D SuperPoint feature maps and 3D fused feature cloud.
 
## Env setup

Clone the code:
```bash
git clone https://github.com/zhaihongjia/SplatLoc --recursive
cd SplatLoc
```

If you failed to get submodules, you can:
```bash
git clone https://github.com/zhaihongjia/SplatLoc
cd SplatLoc/submodules

git clone --recursive https://github.com/cvg/Hierarchical-Localization/
git clone https://gitlab.inria.fr/bkerbl/simple-knn.git
git clone https://github.com/zhaihongjia/diff-gaussian-rasterization.git
```

Setup the environment:

```bash
conda env create -f environment.yml
conda activate splatloc

pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch
```

Then, run following scripts:
```bash
cd submodules/diff-gaussian-rasterization
pip install -e .
```

## Dataset

You can download the datasets from [Replica](https://www.dropbox.com/scl/fo/puh6djua6ewgs0afsswmz/AGudMbll0n0v_iADmqrrRds?rlkey=ep5495umv628y2sk8hvnh8msc&e=1&dl=0) provided by Semantic-NeRF and [12-Scenes](http://graphics.stanford.edu/projects/reloc/#data).

## Generated retrieval results and SuperPoint feature clound

Currently, we provide the data generated by ours. You can find it at [Google Drive](https://drive.google.com/file/d/1MkZvLV6DakUHEE0RHplJqxa-iuUWn59z/view?usp=drive_link).
You can download the data and set the path `generated_folder` in the configs. The preprocessing codes (retrieval and feature volume reconstruction) will be released later.

## Train 3D Gaussian and feature decoder 

Before training, you may set the following parameters of the `xxxx.yaml` in the `configs` folder.

```
generated_folder: to load the generated data provided by ours
save_dir: to save your results
dataset_path: to load your dataset
```

Running the following scripts to train model and evaluate performance:
```bash
sh replica.sh
sh scenes12.sh
```

For more details, we show the codes for train and test on a scene in `Replica` dataset.
```bash
# train the 3D feature decoder
CUDA_VISIBLE_DEVICES=1 python train_decoder.py --config ./configs/replica_nerf/$scene.yaml

# train the 3D gaussian model
CUDA_VISIBLE_DEVICES=1 python train_gaussians.py --config ./configs/replica_nerf/$scene.yaml

# eval localization and rendering
CUDA_VISIBLE_DEVICES=1 python test.py --config ./configs/replica_nerf/$scene.yaml --eval_pose --eval_rendering 

# eval 3D landmark selection (with 5000 landmarks)
CUDA_VISIBLE_DEVICES=1 python test.py --config ./configs/replica_nerf/$scene.yaml --eval_selection --landmark_num 5000
```

The saved ply and evaluation results are stored in your `save_dir` in the `base_config.yaml`.

- point_cloud: saved 3D Gaussian model
- train_feat: saved 3D decoder 
- eval_rendering.txt: rendering performance
- eval_pose.txt: localization performance
- eval_selection_xx.txt: localization performance of xx selected 3D landmarks

## Acknowledgement
This work incorporates many open-source codes. We extend our gratitude to the authors of the software.
- [3D Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting)
- [MonoGS](https://github.com/muskie82/MonoGS)
- [Differential Gaussian Rasterization](https://github.com/zhaihongjia/diff-gaussian-rasterization)
- [Hierarchical-Localization](https://github.com/cvg/Hierarchical-Localization)
- [SceneLandmarkLocalization](https://github.com/microsoft/SceneLandmarkLocalization)

## Citation
If you found this code/work to be useful in your own research, please considering citing the following:

```bibtex
@article{zhai2025splatloc,
  title={{SplatLoc}: 3D Gaussian Splatting-based Visual Localization for Augmented Reality}, 
  author={Zhai, Hongjia and Zhang, Xiyu and Zhao, Boming and Li, Hai and He, Yijia and Cui, Zhaopeng and Bao, Hujun and Zhang, Guofeng},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2025},
  volume={31},
  number={5},
  pages={3591-3601},
}
```